{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tsetline Machine \n",
        "Tsetlin machine (TM) is a recently developed machine learning system based on automata (finite state machines / propositional logic) learning. Please see [this paper](https://arxiv.org/abs/1804.01508) for details. \n",
        "\n",
        "TM is said to be competitive on many tasks with other ML methods (both DL & classical). However, the main draw is that TM-based models are faster to train and more energy-efficient when used for inferencing than models based on other ML methods - while providing similar accuracy. As ML becomes pervasive, the compute and power costs of deployed models becomes non-trivial. TM may help to reign in runtime and training costs associated with ML at scale.\n",
        "\n",
        "This notebook demonstrates how PyTorch (or TorchSharp) may be used to train a TM. The objective is to parallelize training by taking advantage of GPU hardware. This implementation, as much as is feasible, relies on the available tensor operations in PyTorch so that the maximum amount of computation can be performed on the GPU.\n",
        "\n",
        "Although this implementation is in F#, the goal is to define a largely language-agnostic computation approach that can be easily ported to other languages (e.g. Python, Java, etc.), as long as the language has a binding to libtorch - the C++ library underlying PyTorch.\n",
        "\n",
        "There are other GPU implementations available (see [github repo](https://github.com/cair/TsetlinMachine)). None of these use tensor operations from a standard tensor library. By using PyTorch as an established standard, the desire is to gain wider deployment portability. For example, the TM may be trained on a GPU but later deployed to a CPU-based environment for inferencing, to save costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "fsharp"
        },
        "vscode": {
          "languageId": "dotnet-interactive.fsharp"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>TorchSharp, 0.96.0</span></li></ul></div></div>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#r \"nuget: TorchSharp, 0.95.5\"\n",
        "#r \"nuget: libtorch-cuda-11.3-win-x64, 1.10.0.1\"  //GPU package takes a while to download (9GB)\n",
        "//#r \"nuget: libtorch-cpu, 1.10.0.1\"\n",
        "open TorchSharp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Payout Matrix\n",
        "TM learning utilizes a game-theoretic feedback mechanism. The core of games is a payout matrix. The penalty / reward / inaction associated with the various 'outcomes' is defined below. Please refer to the paper for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "fsharp"
        },
        "vscode": {
          "languageId": "dotnet-interactive.fsharp"
        }
      },
      "outputs": [],
      "source": [
        "let inaction = 0.0f\n",
        "let pnlty    = -1.0f\n",
        "\n",
        "let payout s = \n",
        "    let ``1/s``     = 1.0f / s\n",
        "    let ``(s-1)/s`` = (s - 1.0f) / s\n",
        "    [|\n",
        "    (*polarity    literal     action  Cw  y     p_reward *)\n",
        "    (*0           0           0       0   0 *)  ``1/s``         //0\n",
        "    (*0           0           0       0   1 *)  inaction        //1\n",
        "    (*0           0           0       1   0 *)  inaction        //2\n",
        "    (*0           0           0       1   1 *)  ``1/s``         //3\n",
        "    (*0           0           1       0   0 *)  -``1/s``        //4\n",
        "    (*0           0           1       0   1 *)  inaction        //5\n",
        "    (*0           0           1       1   0 *)  inaction        //6\n",
        "    (*0           0           1       1   1 *)  -``1/s``        //7\n",
        "    (*0           1           0       0   0 *)  ``1/s``         //8\n",
        "    (*0           1           0       0   1 *)  inaction        //9\n",
        "    (*0           1           0       1   0 *)  inaction        //10\n",
        "    (*0           1           0       1   1 *)  ``1/s``         //11\n",
        "    (*0           1           1       0   0 *)  -``1/s``        //12\n",
        "    (*0           1           1       0   1 *)  inaction        //13\n",
        "    (*0           1           1       1   0 *)  inaction        //14\n",
        "    (*0           1           1       1   1 *)  -``1/s``        //15\n",
        "    (*1           0           0       0   0 *)  ``1/s``         //16\n",
        "    (*1           0           0       0   1 *)  pnlty           //17\n",
        "    (*1           0           0       1   0 *)  pnlty           //18\n",
        "    (*1           0           0       1   1 *)  ``1/s``         //19\n",
        "    (*1           0           1       0   0 *)  inaction        //20\n",
        "    (*1           0           1       0   1 *)  inaction        //21\n",
        "    (*1           0           1       1   0 *)  inaction        //22\n",
        "    (*1           0           1       1   1 *)  inaction        //23\n",
        "    (*1           1           0       0   0 *)  -``1/s``        //24\n",
        "    (*1           1           0       0   1 *)  inaction        //25\n",
        "    (*1           1           0       1   0 *)  inaction        //26\n",
        "    (*1           1           0       1   1 *)  -``1/s``        //27\n",
        "    (*1           1           1       0   0 *)  ``(s-1)/s``     //28\n",
        "    (*1           1           1       0   1 *)  inaction        //29\n",
        "\n",
        "    (*1           1           1       1   0 *)  inaction        //30\n",
        "    (*1           1           1       1   1 *)  ``(s-1)/s``     //31\n",
        "    |]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train\n",
        "Functions to train (and evaluate) Tsetline machine clauses from input data using PyTorch (TorchSharp) tensor operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "fsharp"
        },
        "vscode": {
          "languageId": "dotnet-interactive.fsharp"
        }
      },
      "outputs": [],
      "source": [
        "//eval each literal against each tsetlin automaton (TA) in the clauses\n",
        "let evalTA trainMode (input:torch.Tensor) (clauses:torch.Tensor) = \n",
        "    let input2 = input.broadcast_to(clauses.shape)\n",
        "    use t3 = torch.tensor(3uy)\n",
        "    use filter = clauses.greater(t3)\n",
        "    use omask = if trainMode then torch.ones_like(input2) else torch.zeros_like(input2)   //default to 1 for training and 0 for evaluation\n",
        "    torch.where(filter,input2,omask)\n",
        "\n",
        "//AND the outputs of TAs by clause\n",
        "let andClause (evals:torch.Tensor)  =\n",
        "    use prods = evals.cumprod(1L,``type``=torch.int8)\n",
        "    prods.[torch.TensorIndex.Ellipsis,torch.TensorIndex.Single(-1L)]\n",
        "\n",
        "//sum positive and negative polarity clause outputs\n",
        "let sumClauses (clauseEvals:torch.Tensor) (plrtySgn:torch.Tensor) =\n",
        "    use withPlry = clauseEvals.mul(plrtySgn)\n",
        "    withPlry.sum().to_type(torch.float32)\n",
        "\n",
        "//obtain +/- reward probabilities for each TA (for type I and II feedback)\n",
        "let rewardProb (payoutMatrix:torch.Tensor) (input:torch.Tensor) (clauses:torch.Tensor) (clauseEvals:torch.Tensor) (polarity:torch.Tensor) (y:torch.Tensor) =\n",
        "    use t3 = torch.tensor([|3y|])\n",
        "    use filter = clauses.greater(t3)\n",
        "    use zs = torch.zeros_like(clauses)\n",
        "    use os = torch.ones_like(clauses)\n",
        "    let ce_t = clauseEvals.reshape(-1L,1L)\n",
        "    (*polarity    literal     action  Cw  y   ->  p_reward *)\n",
        "    let polarity_f = polarity.expand_as(clauses).reshape([|1L;-1L|]).to_type(torch.int64)\n",
        "    let literal_f = input.expand_as(clauses).reshape([|1L;-1L|]).to_type(torch.int64)\n",
        "    let action_f = torch.where(filter,os,zs).reshape([|1L;-1L|]).to_type(torch.int64)\n",
        "    let cw_f = torch.hstack(ResizeArray[for _ in 1 .. int input.shape.[0] -> ce_t]).reshape([|1L;-1L|]).to_type(torch.int64)\n",
        "    let y_f = y.expand_as(clauses).reshape([|1L;-1L|]).to_type(torch.int64)\n",
        "    payoutMatrix.index([|polarity_f; literal_f; action_f; cw_f; y_f|])\n",
        "\n",
        "//postive, negative or no feedback for each TA\n",
        "let taFeeback (T:float32) (v:torch.Tensor) (pReward:torch.Tensor) (y:torch.Tensor) =\n",
        "    use tPlus = torch.tensor(T)\n",
        "    use tMinus = torch.tensor(-T)\n",
        "    use t2 = (2.0f * T).ToScalar()\n",
        "    use selY1 = (tPlus - v.clamp(tMinus,tPlus)) / t2  //feedback selection prob. when y=1\n",
        "    use selY0 = (tPlus + v.clamp(tMinus,tPlus)) / t2  //feedback selection prob. when y=0 \n",
        "    use uRand = torch.rand_like(pReward)              //tensor of uniform random values (for feedback selection)\n",
        "    use feebackFilter =                               //bool tensor; true if random <= [selY0 or selY1] (based on the value of y )\n",
        "        if y.ToSingle() <= 0.f then \n",
        "            uRand.less_equal(selY0) \n",
        "        else \n",
        "            uRand.less(selY1)                      \n",
        "    use zeros = torch.zeros_like(pReward)                 //zero filled tensor - same shape as reward probabilities\n",
        "    use pRewardSel = pReward.where(feebackFilter,zeros)   //keep reward prob if filter tensor value is true, zero otherwise\n",
        "    use negRewards = pRewardSel.minimum(zeros)          //separate out negative reward prob.\n",
        "    use posRewards = pRewardSel.maximum(zeros)          //separate out postive reward prob.\n",
        "    use uRandRwrd = torch.rand_like(pRewardSel)         //tensor of uniform random values for reward selection\n",
        "    use negRwdFltr = uRandRwrd.less_equal(negRewards.abs_()) //negative reward filter reflecting random selection\n",
        "    use posRwdFltr = uRandRwrd.less_equal(posRewards)        //positive reward filter reflecting random selection\n",
        "    use negOnes = torch.full_like(pRewardSel,-1, dtype=torch.uint8)     //negative ones - will be used for negative feedback\n",
        "    use posOnes = torch.full_like(pRewardSel, 1, dtype=torch.uint8)     //positive ones - will be used for positive feedback\n",
        "    use zerosI8 = torch.zeros_like(pRewardSel,dtype=torch.uint8)        \n",
        "    use negFeedback = negOnes.where(negRwdFltr,zerosI8)\n",
        "    use posFeedback = posOnes.where(posRwdFltr,zerosI8)\n",
        "    use feedbackByte = negFeedback + posFeedback\n",
        "    feedbackByte.to_type(torch.int8)                                 //final feedback tensor with -1, +1 or 0 values \n",
        "\n",
        "//inplace update clauses\n",
        "let updateClauses_ (clauses:torch.Tensor) (feedback:torch.Tensor) =\n",
        "    clauses.add_(feedback.reshape(clauses.shape)).clamp_(1uy,6uy)\n",
        "\n",
        "//udpated clauses as a new tensor\n",
        "let updateClauses (clauses:torch.Tensor) (feedback:torch.Tensor) =\n",
        "    clauses.add(feedback.reshape(clauses.shape)).clamp_(1uy,6uy)\n",
        "\n",
        "//update clauses on single input - optimized for producton\n",
        "let trainStep  T payoutMatrix (polarity,plrtySgn) clauses (input,y) = \n",
        "    use taEvals = evalTA true input clauses //num_clauses * input\n",
        "    use clauseEvals = andClause taEvals\n",
        "    use v = sumClauses clauseEvals plrtySgn\n",
        "    use pReward = rewardProb payoutMatrix input clauses clauseEvals polarity y\n",
        "    use feedback = taFeeback T v pReward y\n",
        "    updateClauses_ clauses feedback |> ignore\n",
        "\n",
        "//debug version of update that returns intermediate results\n",
        "let trainStepDbg T payoutMatrix (polarity,plrtySgn) clauses (input,y)  =\n",
        "    let taEvals = evalTA true input clauses //num_clauses * input\n",
        "    let clauseEvals = andClause taEvals\n",
        "    let v = sumClauses clauseEvals plrtySgn\n",
        "    let pReward = rewardProb payoutMatrix input clauses clauseEvals polarity y\n",
        "    let feedback = taFeeback T v pReward y\n",
        "    let updtClss = updateClauses clauses feedback \n",
        "    taEvals,clauseEvals,v,pReward,feedback,updtClss\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing\n",
        "The following is a simple 2-clause Testline machine of polarity 0 and 1, resp. It accepts a 2-bit input (4-bits when input is extended with negations, as required). Threfore each clause has 4 Tsetlin automaton. \n",
        "\n",
        "The machine updated with a single input observation where X = [|1;0;0;1|] and Y = 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "fsharp"
        },
        "vscode": {
          "languageId": "dotnet-interactive.fsharp"
        }
      },
      "outputs": [],
      "source": [
        "//hyper-parameters\n",
        "let s = 3.0f\n",
        "let T = 5.0f\n",
        "let payoutMatrix = torch.tensor(payout s, dimensions = [|2L;2L;2L;2L;2L|])                  //construct the payout matrix from the s hyper-parameter\n",
        "let X = torch.tensor([|1;0;0;1|],dtype=torch.int8)                                          //x = 1,0 (plus negated)\n",
        "let y = torch.tensor([|0|],dtype=torch.int8)                                                //y = 0\n",
        "let clauses = torch.tensor([|1;5;6;2\n",
        "                             1;3;2;6|],dimensions=[|2L; 4L|],dtype=torch.int8)              //2-clause TM - each value reflects an automaton state\n",
        "let polarity = torch.tensor([|1;0|],dimensions=[|clauses.shape.[0];1L|],dtype=torch.int8)   //polarity of the clauses as 0/1 \n",
        "let plrtySgn = torch.tensor([|1;-1|],dimensions=[|clauses.shape.[0];1L|],dtype=torch.int8)  //polarity of the clasues as +/- (these need to be created once only)\n",
        "\n",
        "//utility function to get raw tensor data as a flat array (shape is not retained)\n",
        "let tensorData<'a when 'a: (new: unit -> 'a) and  'a: struct and 'a :> ValueType>(t:torch.Tensor) = t.data<'a>().ToArray()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Update TM using a single oberservation (X,y)\n",
        "Perform a single update step on the TM using the debug version of the training step function. The debug version returns the intermedate values as well as the updated clauses. The input (X,y) , intermedidate values and clause states (before and after) are printed to the console for inspection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "dotnet_interactive": {
          "language": "fsharp"
        },
        "vscode": {
          "languageId": "dotnet-interactive.fsharp"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.code.notebook.stdout": [
              "X: [|1y; 0y; 0y; 1y|], y: 0\r\n",
              "orig clauses: [|1y; 5y; 6y; 2y; 1y; 3y; 2y; 6y|]\r\n",
              "taEvals: [|1y; 0y; 0y; 1y; 1y; 1y; 1y; 1y|]\r\n",
              "clauseEvals: [|0y; 1y|]\r\n",
              "v: [|0.0f|]\r\n",
              "pReward: [|-0.3333333433f; 0.0f; 0.0f; -0.3333333433f; 0.0f; 0.0f; 0.0f; 0.0f|]\r\n",
              "feedback (randomized): [|0y; 0y; 0y; -1y; 0y; 0y; 0y; 0y|]\r\n",
              "updt clauses: [|1y; 5y; 6y; 1y; 1y; 3y; 2y; 6y|]\r\n"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "let (taEvals,clauseEvals,v,pReward,feedback,updtClss) = trainStepDbg T payoutMatrix (polarity,plrtySgn) clauses (X,y) \n",
        "printfn \"X: %A, y: %A\" (tensorData<int8> input) (y.ToInt32())\n",
        "printfn \"orig clauses: %A\" (tensorData<int8> clauses)\n",
        "printfn \"taEvals: %A\" (tensorData<int8> taEvals)\n",
        "printfn \"clauseEvals: %A\" (tensorData<int8> clauseEvals)\n",
        "printfn \"v: %A\" (tensorData<float32> v)\n",
        "printfn \"pReward: %A\" (tensorData<float32> pReward)\n",
        "printfn \"feedback (randomized): %A\" (tensorData<int8> feedback)\n",
        "printfn \"updt clauses: %A\" (tensorData<int8> updtClss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Summary and Next Steps\n",
        "The goal of this notebook is to showcase the use of tensor operations as a feasible means of training Tsetlin machines on GPUs. It is intended for better understanding Tsetline machines internals and for debuging and troubleshooting (it may not be fully correct).\n",
        "\n",
        "Planned is a library / package that provides a high-level API to train Testlin machines using PyTorch tensor operations. The implementation here can only address binary classification problems. Many real-world problems are mult-class. Fornuately, there is an easy way to extend TM to handle multi-class problems. Support for multi-class is also planned.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".NET (C#)",
      "language": "C#",
      "name": ".net-csharp"
    },
    "language_info": {
      "file_extension": ".cs",
      "mimetype": "text/x-csharp",
      "name": "C#",
      "pygments_lexer": "csharp",
      "version": "8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
